{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Import\n",
    "- Read data (vocab, sentences)\n",
    "- Build model using Luong attention\n",
    "- Train model\n",
    "- Evaluating model\n",
    "- Compute BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:50.967384Z",
     "start_time": "2018-03-22T10:38:50.962358Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T04:01:55.240626Z",
     "start_time": "2018-03-21T04:01:55.235314Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:51.570654Z",
     "start_time": "2018-03-22T10:38:50.972246Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "\n",
    "import scripts.text\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:51.578741Z",
     "start_time": "2018-03-22T10:38:51.574719Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path = './processed-data/id.1000/'\n",
    "en_vocab_path = data_path + 'train.10k.en.vocab'\n",
    "de_vocab_path = data_path + 'train.10k.de.vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:51.610293Z",
     "start_time": "2018-03-22T10:38:51.582575Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading vocab file ./processed-data/id.1000/train.10k.en.vocab ...\n",
      "  num words = 1000\n",
      "# Loading vocab file ./processed-data/id.1000/train.10k.de.vocab ...\n",
      "  num words = 1000\n"
     ]
    }
   ],
   "source": [
    "en_words, en_vocab, _ = scripts.text.load_vocab(en_vocab_path)\n",
    "de_words, de_vocab, _ = scripts.text.load_vocab(de_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:51.941530Z",
     "start_time": "2018-03-22T10:38:51.614135Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read train data\n",
    "en_train_sentences = []\n",
    "with open(data_path + 'train.10k.en', 'r') as f:\n",
    "    for line in f:\n",
    "        en_train_sentences.append(map(lambda x: int(x), line.split()))\n",
    "        \n",
    "de_train_sentences = []\n",
    "with open(data_path + 'train.10k.de', 'r') as f:\n",
    "    for line in f:\n",
    "        de_train_sentences.append(map(lambda x: int(x), line.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:51.955103Z",
     "start_time": "2018-03-22T10:38:51.945386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read validation data\n",
    "en_valid_sentences = []\n",
    "with open(data_path + 'valid.100.en', 'r') as f:\n",
    "    for line in f:\n",
    "        en_valid_sentences.append(map(lambda x: int(x), line.split()))\n",
    "        \n",
    "de_valid_sentences = []\n",
    "with open(data_path + 'valid.100.de', 'r') as f:\n",
    "    for line in f:\n",
    "        de_valid_sentences.append(map(lambda x: int(x), line.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RNNs + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:51.985901Z",
     "start_time": "2018-03-22T10:38:51.958984Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Model's encoder using RNN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n",
    "\n",
    "    def forward(self, input_sentence, hidden):\n",
    "        sentence_len = len(input_sentence)\n",
    "        \n",
    "        embedded = self.embedding(input_sentence)\n",
    "        embedded = embedded.view(sentence_len, batch_size, -1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:52.030989Z",
     "start_time": "2018-03-22T10:38:51.989919Z"
    }
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "        Attention class.\n",
    "    \"\"\"\n",
    "    def __init__(self, method, hidden_size, max_length=MAX_LENGTH):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "#         self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attention = nn.Linear(self.hidden_size, hidden_size)\n",
    "            \n",
    "        elif self.method == 'concat':\n",
    "            self.attention = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "            \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        sequence_len = len(encoder_outputs)\n",
    "        \n",
    "        # Create variable to store attention weights\n",
    "        attention_energies = Variable(torch.zeros(sequence_len)) # B x 1 x S\n",
    "        if use_cuda:\n",
    "            attention_energies = attention_energies.cuda()\n",
    "        \n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(sequence_len):\n",
    "            attention_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "        \n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x sequence length\n",
    "        return F.softmax(attention_energies, dim=-1).view(1, 1, sequence_len)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attention(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attention(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.other.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:52.095276Z",
     "start_time": "2018-03-22T10:38:52.040267Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Decoder using Attention mechanism.\n",
    "    \"\"\"\n",
    "    def __init__(self, attention_model, hidden_size, output_size, num_layers=1,\n",
    "                 dropout_p=0.1):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.attention_model = attention_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, num_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attention_model != 'none':\n",
    "            self.attention = Attention(attention_model, hidden_size)\n",
    "        \n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        # Combine embedded input word and last context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "        attention_weights = self.attention(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attention_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1) # B x S=1 x N -> B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)), dim=1)\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, context, hidden, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RNN + Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Checking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:56:12.843640Z",
     "start_time": "2018-03-22T09:56:12.834240Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (rnn): GRU(10, 10)\n",
      ")\n",
      "AttentionDecoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(20, 10, dropout=0.1)\n",
      "  (out): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (attention): Attention(\n",
      "    (attention): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 10, 1)\n",
    "decoder_test = AttentionDecoderRNN('general', 10, 10, 1)\n",
    "print(encoder_test)\n",
    "print(decoder_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:56:26.151718Z",
     "start_time": "2018-03-22T09:56:22.218414Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10]) torch.Size([1, 1, 10]) torch.Size([1, 1, 3])\n",
      "torch.Size([1, 10]) torch.Size([1, 1, 10]) torch.Size([1, 1, 3])\n",
      "torch.Size([1, 10]) torch.Size([1, 1, 10]) torch.Size([1, 1, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theqs-intern/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/theqs-intern/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "if use_cuda:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3]))\n",
    "decoder_attns = torch.zeros(1, 3, 3).cuda()\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "if use_cuda:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "for i in range(3):\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_inputs[i], decoder_context, decoder_hidden, encoder_outputs)\n",
    "    print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:52.110058Z",
     "start_time": "2018-03-22T10:38:52.097989Z"
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "MAX_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:52.189928Z",
     "start_time": "2018-03-22T10:38:52.117281Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # Zero gradient\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Prepare input for decoder and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[de_vocab['<s>']]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden  # Use last hidden from the encoder\n",
    "\n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: use the ground-truth target as the next input\n",
    "        for d_i in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[d_i])\n",
    "            decoder_input = target_variable[d_i]\n",
    "    else:\n",
    "        # Without teacher forcing use its own predictions as the next input\n",
    "        for d_i in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "#             print(decoder_output)\n",
    "            loss += criterion(decoder_output, target_variable[d_i])\n",
    "            # Pick most likely word index (highest value) from output (greedy search)\n",
    "            top_value, top_index = decoder_output.data.topk(1)\n",
    "            n_i = top_index[0][0]\n",
    "#             print(n_i)\n",
    "#             print(torch.LongTensor([n_i]))\n",
    "            decoder_input = Variable(torch.LongTensor([[n_i]])) # Chosen word is next input\n",
    "            \n",
    "            if use_cuda:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targers)\n",
    "            if n_i == en_vocab['</s>']:\n",
    "                break\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:55.965974Z",
     "start_time": "2018-03-22T10:38:52.198886Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_size = 64\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "dropout_p = 0.00\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(len(en_vocab), embedding_size, hidden_size, num_layers)\n",
    "decoder = AttentionDecoderRNN('dot', hidden_size, len(de_vocab), num_layers)\n",
    "\n",
    "# Move models to GPU\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "# Initialize parameters and criterion\n",
    "# learning_rate = 0.0001\n",
    "# encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# decoder_optimizer = torch.optim.SGD(decoder.parameters(), lr=learning_rate, momentum=0.9)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T10:38:55.975522Z",
     "start_time": "2018-03-22T10:38:55.969841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "num_epochs = 1\n",
    "plot_every = 100\n",
    "print_every = 100\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print every\n",
    "plot_loss_total = 0 # Reset every plot every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T10:38:50.970Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all sentences to Variable\n",
    "if use_cuda:\n",
    "    for i in range(len(en_train_sentences)):\n",
    "        en_train_sentences[i] = Variable(torch.LongTensor(en_train_sentences[i]).view(-1, 1)).cuda()\n",
    "        de_train_sentences[i] = Variable(torch.LongTensor(de_train_sentences[i]).view(-1, 1)).cuda()\n",
    "else:\n",
    "    for i in range(len(en_train_sentences)):\n",
    "        en_train_sentences[i] = Variable(torch.LongTensor(en_train_sentences[i]).view(-1, 1))\n",
    "        de_train_sentences[i] = Variable(torch.LongTensor(de_train_sentences[i]).view(-1, 1))\n",
    "\n",
    "if use_cuda:\n",
    "    for i in range(len(en_valid_sentences)):\n",
    "        en_valid_sentences[i] = Variable(torch.LongTensor(en_valid_sentences[i]).view(-1, 1)).cuda()\n",
    "        de_valid_sentences[i] = Variable(torch.LongTensor(de_valid_sentences[i]).view(-1, 1)).cuda()\n",
    "else:\n",
    "    for i in range(len(en_valid_sentences)):\n",
    "        en_valid_sentences[i] = Variable(torch.LongTensor(en_valid_sentences[i]).view(-1, 1))\n",
    "        de_valid_sentences[i] = Variable(torch.LongTensor(de_valid_sentences[i]).view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T10:38:50.972Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for epoch in range(0, num_epochs):\n",
    "    #start epoch\n",
    "    # Shuffle\n",
    "    indexes = np.arange(0, len(en_train_sentences))\n",
    "    np.random.shuffle(indexes)\n",
    "    step = 1\n",
    "    num_steps = math.ceil(len(en_train_sentences) / batch_size)\n",
    "    for index in indexes:\n",
    "        input_variable = en_train_sentences[index]\n",
    "        target_variable = de_train_sentences[index]\n",
    "        loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if step == 0:\n",
    "            step += 1\n",
    "            continue\n",
    "        \n",
    "        if step % print_every == 0 or step == num_steps:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print_summary = 'Epoch %s/%s, Time: %s, Step: %d/%d, train_loss: %.4f' % (epoch, num_epochs,\n",
    "                                                                utils.time_since(start, step / num_steps),\n",
    "                                                                step,\n",
    "                                                                num_steps, print_loss_avg)\n",
    "            print(print_summary)\n",
    "        \n",
    "        if step % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total\n",
    "        step += 1\n",
    "    # end epoch\n",
    "    # evaluate on validation set\n",
    "    valid_total_loss = 0\n",
    "    for i in range(len(en_valid_sentences)):\n",
    "        input_variable = en_valid_sentences[i]\n",
    "        output_varible = de_valid_sentences[i]\n",
    "        valid_loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, criterion)\n",
    "        valid_total_loss += valid_loss\n",
    "    print('Validation loss: %.4f' % (valid_total_loss / len(en_valid_sentences)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T10:38:50.975Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = Variable(torch.LongTensor(scripts.text.to_id(sentence.split(), en_vocab)))\n",
    "    if use_cuda:\n",
    "        input_variable = input_variable.cuda()\n",
    "    \n",
    "    input_length = len(input_variable)\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[de_vocab['<s>']]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    # Run through decoder\n",
    "    for d_i in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input,\n",
    "                    decoder_context, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[d_i, :decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "        # Pick most likely word index (highest value) from output (greedy search)\n",
    "        top_value, top_index = decoder_output.data.topk(1)\n",
    "        n_i = top_index[0][0]\n",
    "\n",
    "        decoded_words += scripts.text.to_text([n_i], de_words)\n",
    "\n",
    "        # Stop at end of sentence (not necessary when using known targers)\n",
    "        if n_i == de_vocab['</s>']:\n",
    "            break\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[n_i]])) # Chosen word is next input\n",
    "\n",
    "        if use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "\n",
    "            \n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T10:38:50.977Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_sentence(s):\n",
    "    valid_sentence = s\n",
    "    \n",
    "    output_words, decoder_attention = evaluate(valid_sentence)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', valid_sentence)\n",
    "#     print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T10:38:50.979Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_sentence('a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "notify_time": "5",
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
