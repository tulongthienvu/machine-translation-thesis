{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Import\n",
    "- Read data (vocab, sentences)\n",
    "- Build model\n",
    "- Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:51.783827Z",
     "start_time": "2018-03-22T09:21:51.778930Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "batch_size = 1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T04:01:55.240626Z",
     "start_time": "2018-03-21T04:01:55.235314Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:52.524119Z",
     "start_time": "2018-03-22T09:21:51.787665Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "\n",
    "import scripts.text\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:52.541586Z",
     "start_time": "2018-03-22T09:21:52.528233Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path = './processed-data/id.1000/'\n",
    "en_vocab_path = data_path + 'train.10k.en.vocab'\n",
    "de_vocab_path = data_path + 'train.10k.de.vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:52.559987Z",
     "start_time": "2018-03-22T09:21:52.544961Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading vocab file ./processed-data/id.1000/train.10k.en.vocab ...\n",
      "  num words = 1000\n",
      "# Loading vocab file ./processed-data/id.1000/train.10k.de.vocab ...\n",
      "  num words = 1000\n"
     ]
    }
   ],
   "source": [
    "en_words, en_vocab, _ = scripts.text.load_vocab(en_vocab_path)\n",
    "de_words, de_vocab, _ = scripts.text.load_vocab(de_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:53.002155Z",
     "start_time": "2018-03-22T09:21:52.567875Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read train data\n",
    "en_train_sentences = []\n",
    "with open(data_path + 'train.10k.en', 'r') as f:\n",
    "    for line in f:\n",
    "        en_train_sentences.append(map(lambda x: int(x), line.split()))\n",
    "        \n",
    "de_train_sentences = []\n",
    "with open(data_path + 'train.10k.de', 'r') as f:\n",
    "    for line in f:\n",
    "        de_train_sentences.append(map(lambda x: int(x), line.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:53.024596Z",
     "start_time": "2018-03-22T09:21:53.006169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read validation data\n",
    "en_valid_sentences = []\n",
    "with open(data_path + 'valid.100.en', 'r') as f:\n",
    "    for line in f:\n",
    "        en_valid_sentences.append(map(lambda x: int(x), line.split()))\n",
    "        \n",
    "de_valid_sentences = []\n",
    "with open(data_path + 'valid.100.de', 'r') as f:\n",
    "    for line in f:\n",
    "        de_valid_sentences.append(map(lambda x: int(x), line.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:53.056566Z",
     "start_time": "2018-03-22T09:21:53.029234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Model's encoder using RNN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n",
    "\n",
    "    def forward(self, input_sentence, hidden):\n",
    "        sentence_len = len(input_sentence)\n",
    "        \n",
    "        embedded = self.embedding(input_sentence)\n",
    "        embedded = embedded.view(sentence_len, batch_size, -1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:53.079431Z",
     "start_time": "2018-03-22T09:21:53.061734Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Model's decoder using RNN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_vector, hidden):\n",
    "        output = self.embedding(input_vector).view(1, batch_size, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output = self.log_softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Checking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T06:47:13.050299Z",
     "start_time": "2018-03-21T06:47:13.043015Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 20, 2)\n",
    "decoder_test = DecoderRNN(10, 20, 10, 2)\n",
    "print(encoder_test)\n",
    "print(decoder_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T06:47:17.096257Z",
     "start_time": "2018-03-21T06:47:13.054397Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "if use_cuda:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3, 4]))\n",
    "decoder_hidden = encoder_hidden\n",
    "\n",
    "if use_cuda:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "\n",
    "for i in range(4):\n",
    "    decoder_output, decoder_hidden = decoder_test(word_inputs[i], decoder_hidden)\n",
    "    print(decoder_output)\n",
    "    print(decoder_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:53.088131Z",
     "start_time": "2018-03-22T09:21:53.083426Z"
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "MAX_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:53.157216Z",
     "start_time": "2018-03-22T09:21:53.092133Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # Zero gradient\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Prepare input for decoder and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[de_vocab['<s>']]]))\n",
    "    decoder_hidden = encoder_hidden  # Use last hidden from the encoder\n",
    "\n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: use the ground-truth target as the next input\n",
    "        for d_i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[d_i])\n",
    "            decoder_input = target_variable[d_i]\n",
    "    else:\n",
    "        # Without teacher forcing use its own predictions as the next input\n",
    "        for d_i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "#             print(decoder_output)\n",
    "            loss += criterion(decoder_output, target_variable[d_i])\n",
    "            # Pick most likely word index (highest value) from output (greedy search)\n",
    "            top_value, top_index = decoder_output.data.topk(1)\n",
    "            n_i = top_index[0][0]\n",
    "#             print(n_i)\n",
    "#             print(torch.LongTensor([n_i]))\n",
    "            decoder_input = Variable(torch.LongTensor([[n_i]])) # Chosen word is next input\n",
    "            \n",
    "            if use_cuda:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targers)\n",
    "            if n_i == en_vocab['</s>']:\n",
    "                break\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "#     nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "#     nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:59.230487Z",
     "start_time": "2018-03-22T09:21:53.160254Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_size = 500\n",
    "hidden_size = 500\n",
    "num_layers = 4\n",
    "dropout_p = 0.00\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(len(en_vocab), embedding_size, hidden_size, num_layers)\n",
    "decoder = DecoderRNN(embedding_size, hidden_size, len(de_vocab), num_layers)\n",
    "\n",
    "# Move models to GPU\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "# Initialize parameters and criterion\n",
    "# learning_rate = 0.0001\n",
    "# encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# decoder_optimizer = torch.optim.SGD(decoder.parameters(), lr=learning_rate, momentum=0.9)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T09:21:59.240199Z",
     "start_time": "2018-03-22T09:21:59.234337Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "num_epochs = 1\n",
    "plot_every = 100\n",
    "print_every = 100\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print every\n",
    "plot_loss_total = 0 # Reset every plot every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T09:21:51.794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all sentences to Variable\n",
    "if use_cuda:\n",
    "    for i in range(len(en_train_sentences)):\n",
    "        en_train_sentences[i] = Variable(torch.LongTensor(en_train_sentences[i]).view(-1, 1)).cuda()\n",
    "        de_train_sentences[i] = Variable(torch.LongTensor(de_train_sentences[i]).view(-1, 1)).cuda()\n",
    "else:\n",
    "    for i in range(len(en_train_sentences)):\n",
    "        en_train_sentences[i] = Variable(torch.LongTensor(en_train_sentences[i]).view(-1, 1))\n",
    "        de_train_sentences[i] = Variable(torch.LongTensor(de_train_sentences[i]).view(-1, 1))\n",
    "\n",
    "if use_cuda:\n",
    "    for i in range(len(en_valid_sentences)):\n",
    "        en_valid_sentences[i] = Variable(torch.LongTensor(en_valid_sentences[i]).view(-1, 1)).cuda()\n",
    "        de_valid_sentences[i] = Variable(torch.LongTensor(de_valid_sentences[i]).view(-1, 1)).cuda()\n",
    "else:\n",
    "    for i in range(len(en_valid_sentences)):\n",
    "        en_valid_sentences[i] = Variable(torch.LongTensor(en_valid_sentences[i]).view(-1, 1))\n",
    "        de_valid_sentences[i] = Variable(torch.LongTensor(de_valid_sentences[i]).view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T09:21:51.797Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Time: 0m 18s (- 31m 3s), Step: 100/10000, train_loss: 4.8068\n",
      "Epoch 0/1, Time: 0m 36s (- 29m 43s), Step: 200/10000, train_loss: 4.7536\n",
      "Epoch 0/1, Time: 0m 51s (- 27m 32s), Step: 300/10000, train_loss: 4.5545\n",
      "Epoch 0/1, Time: 1m 6s (- 26m 27s), Step: 400/10000, train_loss: 4.5978\n",
      "Epoch 0/1, Time: 1m 22s (- 26m 14s), Step: 500/10000, train_loss: 4.4612\n",
      "Epoch 0/1, Time: 1m 38s (- 25m 44s), Step: 600/10000, train_loss: 4.6629\n",
      "Epoch 0/1, Time: 1m 55s (- 25m 37s), Step: 700/10000, train_loss: 4.6192\n",
      "Epoch 0/1, Time: 2m 12s (- 25m 25s), Step: 800/10000, train_loss: 4.4722\n",
      "Epoch 0/1, Time: 2m 31s (- 25m 31s), Step: 900/10000, train_loss: 4.3995\n",
      "Epoch 0/1, Time: 2m 47s (- 25m 11s), Step: 1000/10000, train_loss: 4.5654\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(0, num_epochs):\n",
    "    #start epoch\n",
    "    # Shuffle\n",
    "    indexes = np.arange(0, len(en_train_sentences))\n",
    "    np.random.shuffle(indexes)\n",
    "    step = 1\n",
    "    num_steps = math.ceil(len(en_train_sentences) / batch_size)\n",
    "    for index in indexes:\n",
    "        input_variable = en_train_sentences[index]\n",
    "        target_variable = de_train_sentences[index]\n",
    "        loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if step == 0:\n",
    "            step += 1\n",
    "            continue\n",
    "        \n",
    "        if step % print_every == 0 or step == num_steps:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print_summary = 'Epoch %s/%s, Time: %s, Step: %d/%d, train_loss: %.4f' % (epoch, num_epochs,\n",
    "                                                                utils.time_since(start, step / num_steps),\n",
    "                                                                step,\n",
    "                                                                num_steps, print_loss_avg)\n",
    "            print(print_summary)\n",
    "        \n",
    "        if step % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total\n",
    "        step += 1\n",
    "    # end epoch\n",
    "    # evaluate on validation set\n",
    "    valid_total_loss = 0\n",
    "    for i in range(len(en_valid_sentences)):\n",
    "        input_variable = en_valid_sentences[i]\n",
    "        output_varible = de_valid_sentences[i]\n",
    "        valid_loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, criterion)\n",
    "        valid_total_loss += valid_loss\n",
    "    print('Validation loss: %.4f' % (valid_total_loss / len(en_valid_sentences)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T09:21:51.799Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = Variable(torch.LongTensor(scripts.text.to_id(sentence.split(), en_vocab)))\n",
    "    print(input_variable)\n",
    "    if use_cuda:\n",
    "        input_variable = input_variable.cuda()\n",
    "    \n",
    "    input_length = len(input_variable)\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[de_vocab['<s>']]]))\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    decoded_words = []\n",
    "    \n",
    "    # Run through decoder\n",
    "    for d_i in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        # Pick most likely word index (highest value) from output (greedy search)\n",
    "        top_value, top_index = decoder_output.data.topk(1)\n",
    "        n_i = top_index[0][0]\n",
    "        print(n_i)\n",
    "        decoded_words += scripts.text.to_text([n_i], de_words)\n",
    "\n",
    "        # Stop at end of sentence (not necessary when using known targers)\n",
    "        if n_i == de_vocab['</s>']:\n",
    "            break\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[n_i]])) # Chosen word is next input\n",
    "\n",
    "        if use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "\n",
    "            \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T09:21:51.804Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_sentence(s):\n",
    "    valid_sentence = s\n",
    "    \n",
    "    output_words = evaluate(valid_sentence)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', valid_sentence)\n",
    "#     print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T09:21:51.807Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_sentence('i am a student and he is a teacher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T09:21:51.811Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_sentence('luck is no excuse and who has luck is successful')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "notify_time": "5",
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
