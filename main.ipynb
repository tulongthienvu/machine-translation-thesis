{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Import\n",
    "- Read data (vocab, sentences)\n",
    "- Build model\n",
    "- Train model\n",
    "    - Mini-batch\n",
    "- Evaluate model\n",
    "    - Loss\n",
    "    - Perplexity\n",
    "    - BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:43.957572Z",
     "start_time": "2018-03-28T04:40:43.948741Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "batch_size = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T04:01:55.240626Z",
     "start_time": "2018-03-21T04:01:55.235314Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:44.520730Z",
     "start_time": "2018-03-28T04:40:43.960915Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "\n",
    "import scripts.text\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:44.530877Z",
     "start_time": "2018-03-28T04:40:44.525366Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path = './processed-data/id.1000/'\n",
    "en_vocab_path = data_path + 'train.10k.en.vocab'\n",
    "de_vocab_path = data_path + 'train.10k.de.vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:44.549763Z",
     "start_time": "2018-03-28T04:40:44.535417Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading vocab file ./processed-data/id.1000/train.10k.en.vocab ...\n",
      "  num words = 1000\n",
      "# Loading vocab file ./processed-data/id.1000/train.10k.de.vocab ...\n",
      "  num words = 1000\n"
     ]
    }
   ],
   "source": [
    "en_words, en_vocab, _ = scripts.text.load_vocab(en_vocab_path)\n",
    "de_words, de_vocab, _ = scripts.text.load_vocab(de_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:44.934517Z",
     "start_time": "2018-03-28T04:40:44.553352Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read train data\n",
    "en_train_sentences = []\n",
    "with open(data_path + 'train.10k.en', 'r') as f:\n",
    "    for line in f:\n",
    "        en_train_sentences.append(map(lambda x: int(x), line.split()))\n",
    "        \n",
    "de_train_sentences = []\n",
    "with open(data_path + 'train.10k.de', 'r') as f:\n",
    "    for line in f:\n",
    "        de_train_sentences.append(map(lambda x: int(x), line.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:44.951693Z",
     "start_time": "2018-03-28T04:40:44.937140Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read validation data\n",
    "en_valid_sentences = []\n",
    "with open(data_path + 'valid.100.en', 'r') as f:\n",
    "    for line in f:\n",
    "        en_valid_sentences.append(map(lambda x: int(x), line.split()))\n",
    "        \n",
    "de_valid_sentences = []\n",
    "with open(data_path + 'valid.100.de', 'r') as f:\n",
    "    for line in f:\n",
    "        de_valid_sentences.append(map(lambda x: int(x), line.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:44.981880Z",
     "start_time": "2018-03-28T04:40:44.956658Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Model's encoder using RNN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n",
    "\n",
    "    def forward(self, input_sentence, hidden):\n",
    "        sentence_len = len(input_sentence)\n",
    "        \n",
    "        embedded = self.embedding(input_sentence)\n",
    "        embedded = embedded.view(sentence_len, batch_size, -1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:45.010694Z",
     "start_time": "2018-03-28T04:40:44.986663Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Model's decoder using RNN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_vector, hidden):\n",
    "        output = self.embedding(input_vector).view(1, batch_size, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output = self.log_softmax(self.out(output[-1]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Checking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T06:47:13.050299Z",
     "start_time": "2018-03-21T06:47:13.043015Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 20, 2)\n",
    "decoder_test = DecoderRNN(10, 20, 10, 2)\n",
    "print(encoder_test)\n",
    "print(decoder_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T06:47:17.096257Z",
     "start_time": "2018-03-21T06:47:13.054397Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "if use_cuda:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3, 4]))\n",
    "decoder_hidden = encoder_hidden\n",
    "\n",
    "if use_cuda:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "\n",
    "for i in range(4):\n",
    "    decoder_output, decoder_hidden = decoder_test(word_inputs[i], decoder_hidden)\n",
    "    print(decoder_output)\n",
    "    print(decoder_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:45.020931Z",
     "start_time": "2018-03-28T04:40:45.015529Z"
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "MAX_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:45.073785Z",
     "start_time": "2018-03-28T04:40:45.024960Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # Zero gradient\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Prepare input for decoder and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[de_vocab['<s>']]]))\n",
    "    decoder_hidden = encoder_hidden  # Use last hidden from the encoder\n",
    "\n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: use the ground-truth target as the next input\n",
    "        for d_i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[d_i])\n",
    "            decoder_input = target_variable[d_i]\n",
    "    else:\n",
    "        # Without teacher forcing use its own predictions as the next input\n",
    "        for d_i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "#             print(decoder_output)\n",
    "            loss += criterion(decoder_output, target_variable[d_i])\n",
    "            # Pick most likely word index (highest value) from output (greedy search)\n",
    "            top_value, top_index = decoder_output.data.topk(1)\n",
    "            n_i = top_index[0][0]\n",
    "#             print(n_i)\n",
    "#             print(torch.LongTensor([n_i]))\n",
    "            decoder_input = Variable(torch.LongTensor([[n_i]])) # Chosen word is next input\n",
    "            \n",
    "            if use_cuda:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targers)\n",
    "            if n_i == en_vocab['</s>']:\n",
    "                break\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "#     nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "#     nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:48.128767Z",
     "start_time": "2018-03-28T04:40:45.078494Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcsquared/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.py:116: UserWarning: \n",
      "    Found GPU0 GeForce 840M which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "dropout_p = 0.00\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(len(en_vocab), embedding_size, hidden_size, num_layers)\n",
    "decoder = DecoderRNN(embedding_size, hidden_size, len(de_vocab), num_layers)\n",
    "\n",
    "# Move models to GPU\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "# Initialize parameters and criterion\n",
    "# learning_rate = 0.0001\n",
    "# encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "# decoder_optimizer = torch.optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:48.140298Z",
     "start_time": "2018-03-28T04:40:48.133012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "num_epochs = 1\n",
    "plot_every = 100\n",
    "print_every = 100\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print every\n",
    "plot_loss_total = 0 # Reset every plot every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:40:48.646365Z",
     "start_time": "2018-03-28T04:40:48.145468Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all sentences to Variable\n",
    "if use_cuda:\n",
    "    for i in range(len(en_train_sentences)):\n",
    "        en_train_sentences[i] = Variable(torch.LongTensor(en_train_sentences[i]).view(-1, 1)).cuda()\n",
    "        de_train_sentences[i] = Variable(torch.LongTensor(de_train_sentences[i]).view(-1, 1)).cuda()\n",
    "else:\n",
    "    for i in range(len(en_train_sentences)):\n",
    "        en_train_sentences[i] = Variable(torch.LongTensor(en_train_sentences[i]).view(-1, 1))\n",
    "        de_train_sentences[i] = Variable(torch.LongTensor(de_train_sentences[i]).view(-1, 1))\n",
    "\n",
    "if use_cuda:\n",
    "    for i in range(len(en_valid_sentences)):\n",
    "        en_valid_sentences[i] = Variable(torch.LongTensor(en_valid_sentences[i]).view(-1, 1)).cuda()\n",
    "        de_valid_sentences[i] = Variable(torch.LongTensor(de_valid_sentences[i]).view(-1, 1)).cuda()\n",
    "else:\n",
    "    for i in range(len(en_valid_sentences)):\n",
    "        en_valid_sentences[i] = Variable(torch.LongTensor(en_valid_sentences[i]).view(-1, 1))\n",
    "        de_valid_sentences[i] = Variable(torch.LongTensor(de_valid_sentences[i]).view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:46:05.061506Z",
     "start_time": "2018-03-28T04:40:48.650673Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcsquared/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:59: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Time: 0m 2s (- 4m 47s), Step: 100/10000, train_loss: 4.7799\n",
      "Epoch 0/1, Time: 0m 5s (- 4m 38s), Step: 200/10000, train_loss: 4.4297\n",
      "Epoch 0/1, Time: 0m 8s (- 4m 29s), Step: 300/10000, train_loss: 4.4822\n",
      "Epoch 0/1, Time: 0m 10s (- 4m 21s), Step: 400/10000, train_loss: 4.4540\n",
      "Epoch 0/1, Time: 0m 13s (- 4m 25s), Step: 500/10000, train_loss: 4.2084\n",
      "Epoch 0/1, Time: 0m 16s (- 4m 19s), Step: 600/10000, train_loss: 4.3388\n",
      "Epoch 0/1, Time: 0m 19s (- 4m 16s), Step: 700/10000, train_loss: 4.3397\n",
      "Epoch 0/1, Time: 0m 22s (- 4m 13s), Step: 800/10000, train_loss: 4.1701\n",
      "Epoch 0/1, Time: 0m 24s (- 4m 10s), Step: 900/10000, train_loss: 4.1341\n",
      "Epoch 0/1, Time: 0m 27s (- 4m 7s), Step: 1000/10000, train_loss: 4.3401\n",
      "Epoch 0/1, Time: 0m 30s (- 4m 3s), Step: 1100/10000, train_loss: 4.1350\n",
      "Epoch 0/1, Time: 0m 32s (- 3m 58s), Step: 1200/10000, train_loss: 3.9873\n",
      "Epoch 0/1, Time: 0m 35s (- 3m 57s), Step: 1300/10000, train_loss: 4.0106\n",
      "Epoch 0/1, Time: 0m 38s (- 3m 55s), Step: 1400/10000, train_loss: 4.0988\n",
      "Epoch 0/1, Time: 0m 41s (- 3m 53s), Step: 1500/10000, train_loss: 4.1717\n",
      "Epoch 0/1, Time: 0m 44s (- 3m 51s), Step: 1600/10000, train_loss: 4.0996\n",
      "Epoch 0/1, Time: 0m 47s (- 3m 49s), Step: 1700/10000, train_loss: 4.1009\n",
      "Epoch 0/1, Time: 0m 49s (- 3m 47s), Step: 1800/10000, train_loss: 4.0371\n",
      "Epoch 0/1, Time: 0m 52s (- 3m 43s), Step: 1900/10000, train_loss: 4.0372\n",
      "Epoch 0/1, Time: 0m 55s (- 3m 41s), Step: 2000/10000, train_loss: 3.9380\n",
      "Epoch 0/1, Time: 0m 57s (- 3m 37s), Step: 2100/10000, train_loss: 4.0449\n",
      "Epoch 0/1, Time: 1m 0s (- 3m 34s), Step: 2200/10000, train_loss: 4.0992\n",
      "Epoch 0/1, Time: 1m 3s (- 3m 32s), Step: 2300/10000, train_loss: 3.8918\n",
      "Epoch 0/1, Time: 1m 5s (- 3m 28s), Step: 2400/10000, train_loss: 3.8609\n",
      "Epoch 0/1, Time: 1m 8s (- 3m 26s), Step: 2500/10000, train_loss: 4.0886\n",
      "Epoch 0/1, Time: 1m 11s (- 3m 23s), Step: 2600/10000, train_loss: 3.9497\n",
      "Epoch 0/1, Time: 1m 14s (- 3m 20s), Step: 2700/10000, train_loss: 3.9414\n",
      "Epoch 0/1, Time: 1m 17s (- 3m 18s), Step: 2800/10000, train_loss: 3.9938\n",
      "Epoch 0/1, Time: 1m 20s (- 3m 16s), Step: 2900/10000, train_loss: 4.0524\n",
      "Epoch 0/1, Time: 1m 23s (- 3m 13s), Step: 3000/10000, train_loss: 3.8854\n",
      "Epoch 0/1, Time: 1m 25s (- 3m 11s), Step: 3100/10000, train_loss: 3.8892\n",
      "Epoch 0/1, Time: 1m 28s (- 3m 8s), Step: 3200/10000, train_loss: 4.1213\n",
      "Epoch 0/1, Time: 1m 31s (- 3m 6s), Step: 3300/10000, train_loss: 3.9984\n",
      "Epoch 0/1, Time: 1m 34s (- 3m 3s), Step: 3400/10000, train_loss: 3.9243\n",
      "Epoch 0/1, Time: 1m 37s (- 3m 0s), Step: 3500/10000, train_loss: 3.9947\n",
      "Epoch 0/1, Time: 1m 39s (- 2m 57s), Step: 3600/10000, train_loss: 3.8979\n",
      "Epoch 0/1, Time: 1m 45s (- 3m 0s), Step: 3700/10000, train_loss: 3.9201\n",
      "Epoch 0/1, Time: 1m 48s (- 2m 57s), Step: 3800/10000, train_loss: 4.0318\n",
      "Epoch 0/1, Time: 1m 53s (- 2m 57s), Step: 3900/10000, train_loss: 4.0308\n",
      "Epoch 0/1, Time: 2m 0s (- 3m 0s), Step: 4000/10000, train_loss: 4.0373\n",
      "Epoch 0/1, Time: 2m 5s (- 3m 0s), Step: 4100/10000, train_loss: 3.8725\n",
      "Epoch 0/1, Time: 2m 8s (- 2m 57s), Step: 4200/10000, train_loss: 3.9411\n",
      "Epoch 0/1, Time: 2m 12s (- 2m 55s), Step: 4300/10000, train_loss: 3.9626\n",
      "Epoch 0/1, Time: 2m 15s (- 2m 52s), Step: 4400/10000, train_loss: 3.9970\n",
      "Epoch 0/1, Time: 2m 18s (- 2m 49s), Step: 4500/10000, train_loss: 3.8990\n",
      "Epoch 0/1, Time: 2m 21s (- 2m 46s), Step: 4600/10000, train_loss: 3.9927\n",
      "Epoch 0/1, Time: 2m 25s (- 2m 44s), Step: 4700/10000, train_loss: 3.7507\n",
      "Epoch 0/1, Time: 2m 28s (- 2m 41s), Step: 4800/10000, train_loss: 3.9191\n",
      "Epoch 0/1, Time: 2m 32s (- 2m 38s), Step: 4900/10000, train_loss: 3.9300\n",
      "Epoch 0/1, Time: 2m 35s (- 2m 35s), Step: 5000/10000, train_loss: 3.8764\n",
      "Epoch 0/1, Time: 2m 38s (- 2m 32s), Step: 5100/10000, train_loss: 3.7482\n",
      "Epoch 0/1, Time: 2m 42s (- 2m 29s), Step: 5200/10000, train_loss: 3.8482\n",
      "Epoch 0/1, Time: 2m 45s (- 2m 26s), Step: 5300/10000, train_loss: 3.9950\n",
      "Epoch 0/1, Time: 2m 50s (- 2m 24s), Step: 5400/10000, train_loss: 3.9122\n",
      "Epoch 0/1, Time: 2m 52s (- 2m 21s), Step: 5500/10000, train_loss: 3.7816\n",
      "Epoch 0/1, Time: 2m 56s (- 2m 18s), Step: 5600/10000, train_loss: 3.8051\n",
      "Epoch 0/1, Time: 3m 0s (- 2m 16s), Step: 5700/10000, train_loss: 3.7768\n",
      "Epoch 0/1, Time: 3m 3s (- 2m 13s), Step: 5800/10000, train_loss: 3.7891\n",
      "Epoch 0/1, Time: 3m 7s (- 2m 10s), Step: 5900/10000, train_loss: 3.6813\n",
      "Epoch 0/1, Time: 3m 10s (- 2m 6s), Step: 6000/10000, train_loss: 3.6976\n",
      "Epoch 0/1, Time: 3m 14s (- 2m 4s), Step: 6100/10000, train_loss: 3.8607\n",
      "Epoch 0/1, Time: 3m 18s (- 2m 1s), Step: 6200/10000, train_loss: 3.7527\n",
      "Epoch 0/1, Time: 3m 23s (- 1m 59s), Step: 6300/10000, train_loss: 3.8267\n",
      "Epoch 0/1, Time: 3m 27s (- 1m 56s), Step: 6400/10000, train_loss: 3.9297\n",
      "Epoch 0/1, Time: 3m 30s (- 1m 53s), Step: 6500/10000, train_loss: 3.6001\n",
      "Epoch 0/1, Time: 3m 34s (- 1m 50s), Step: 6600/10000, train_loss: 3.7520\n",
      "Epoch 0/1, Time: 3m 39s (- 1m 48s), Step: 6700/10000, train_loss: 3.7364\n",
      "Epoch 0/1, Time: 3m 43s (- 1m 45s), Step: 6800/10000, train_loss: 3.7714\n",
      "Epoch 0/1, Time: 3m 46s (- 1m 41s), Step: 6900/10000, train_loss: 3.6416\n",
      "Epoch 0/1, Time: 3m 48s (- 1m 38s), Step: 7000/10000, train_loss: 3.7676\n",
      "Epoch 0/1, Time: 3m 51s (- 1m 34s), Step: 7100/10000, train_loss: 3.9255\n",
      "Epoch 0/1, Time: 3m 54s (- 1m 31s), Step: 7200/10000, train_loss: 3.7762\n",
      "Epoch 0/1, Time: 3m 56s (- 1m 27s), Step: 7300/10000, train_loss: 3.7352\n",
      "Epoch 0/1, Time: 3m 59s (- 1m 24s), Step: 7400/10000, train_loss: 3.7645\n",
      "Epoch 0/1, Time: 4m 1s (- 1m 20s), Step: 7500/10000, train_loss: 3.8200\n",
      "Epoch 0/1, Time: 4m 4s (- 1m 17s), Step: 7600/10000, train_loss: 3.9227\n",
      "Epoch 0/1, Time: 4m 7s (- 1m 13s), Step: 7700/10000, train_loss: 3.7620\n",
      "Epoch 0/1, Time: 4m 9s (- 1m 10s), Step: 7800/10000, train_loss: 3.9477\n",
      "Epoch 0/1, Time: 4m 12s (- 1m 7s), Step: 7900/10000, train_loss: 3.7987\n",
      "Epoch 0/1, Time: 4m 15s (- 1m 3s), Step: 8000/10000, train_loss: 3.8482\n",
      "Epoch 0/1, Time: 4m 18s (- 1m 0s), Step: 8100/10000, train_loss: 3.8017\n",
      "Epoch 0/1, Time: 4m 21s (- 0m 57s), Step: 8200/10000, train_loss: 3.7725\n",
      "Epoch 0/1, Time: 4m 23s (- 0m 54s), Step: 8300/10000, train_loss: 3.8197\n",
      "Epoch 0/1, Time: 4m 26s (- 0m 50s), Step: 8400/10000, train_loss: 3.7649\n",
      "Epoch 0/1, Time: 4m 29s (- 0m 47s), Step: 8500/10000, train_loss: 3.7350\n",
      "Epoch 0/1, Time: 4m 32s (- 0m 44s), Step: 8600/10000, train_loss: 3.7611\n",
      "Epoch 0/1, Time: 4m 34s (- 0m 41s), Step: 8700/10000, train_loss: 3.8899\n",
      "Epoch 0/1, Time: 4m 37s (- 0m 37s), Step: 8800/10000, train_loss: 3.7184\n",
      "Epoch 0/1, Time: 4m 39s (- 0m 34s), Step: 8900/10000, train_loss: 3.5119\n",
      "Epoch 0/1, Time: 4m 42s (- 0m 31s), Step: 9000/10000, train_loss: 3.8066\n",
      "Epoch 0/1, Time: 4m 45s (- 0m 28s), Step: 9100/10000, train_loss: 3.9185\n",
      "Epoch 0/1, Time: 4m 48s (- 0m 25s), Step: 9200/10000, train_loss: 3.6994\n",
      "Epoch 0/1, Time: 4m 51s (- 0m 21s), Step: 9300/10000, train_loss: 3.7723\n",
      "Epoch 0/1, Time: 4m 54s (- 0m 18s), Step: 9400/10000, train_loss: 3.8234\n",
      "Epoch 0/1, Time: 4m 56s (- 0m 15s), Step: 9500/10000, train_loss: 3.8705\n",
      "Epoch 0/1, Time: 4m 59s (- 0m 12s), Step: 9600/10000, train_loss: 3.7798\n",
      "Epoch 0/1, Time: 5m 2s (- 0m 9s), Step: 9700/10000, train_loss: 3.7156\n",
      "Epoch 0/1, Time: 5m 5s (- 0m 6s), Step: 9800/10000, train_loss: 3.9147\n",
      "Epoch 0/1, Time: 5m 8s (- 0m 3s), Step: 9900/10000, train_loss: 3.9746\n",
      "Epoch 0/1, Time: 5m 11s (- 0m 0s), Step: 10000/10000, train_loss: 3.9315\n",
      "Validation loss: 1.5886\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(0, num_epochs):\n",
    "    #start epoch\n",
    "    # Shuffle\n",
    "    indexes = np.arange(0, len(en_train_sentences))\n",
    "    np.random.shuffle(indexes)\n",
    "    step = 1\n",
    "    num_steps = math.ceil(len(en_train_sentences) / batch_size)\n",
    "    for index in indexes:\n",
    "        input_variable = en_train_sentences[index]\n",
    "        target_variable = de_train_sentences[index]\n",
    "        loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if step == 0:\n",
    "            step += 1\n",
    "            continue\n",
    "        \n",
    "        if step % print_every == 0 or step == num_steps:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print_summary = 'Epoch %s/%s, Time: %s, Step: %d/%d, train_loss: %.4f' % (epoch, num_epochs,\n",
    "                                                                utils.time_since(start, step / num_steps),\n",
    "                                                                step,\n",
    "                                                                num_steps, print_loss_avg)\n",
    "            print(print_summary)\n",
    "        \n",
    "        if step % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total\n",
    "        step += 1\n",
    "        \n",
    "        # stop when reaching certain steps\n",
    "#         if step == 2000:\n",
    "#             break\n",
    "        \n",
    "    # end epoch\n",
    "    # evaluate on validation set\n",
    "    valid_total_loss = 0\n",
    "    for i in range(len(en_valid_sentences)):\n",
    "        input_variable = en_valid_sentences[i]\n",
    "        output_varible = de_valid_sentences[i]\n",
    "        valid_loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, criterion)\n",
    "        valid_total_loss += valid_loss\n",
    "    print('Validation loss: %.4f' % (valid_total_loss / len(en_valid_sentences)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:46:05.099288Z",
     "start_time": "2018-03-28T04:46:05.066665Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = Variable(torch.LongTensor(scripts.text.to_id(sentence.split(), en_vocab)))\n",
    "    print(input_variable)\n",
    "    if use_cuda:\n",
    "        input_variable = input_variable.cuda()\n",
    "    \n",
    "    input_length = len(input_variable)\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[de_vocab['<s>']]]))\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    decoded_words = []\n",
    "    \n",
    "    # Run through decoder\n",
    "    for d_i in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        # Pick most likely word index (highest value) from output (greedy search)\n",
    "        top_value, top_index = decoder_output.data.topk(1)\n",
    "        n_i = top_index[0][0]\n",
    "        print(n_i)\n",
    "        decoded_words += scripts.text.to_text([n_i], de_words)\n",
    "\n",
    "        # Stop at end of sentence (not necessary when using known targers)\n",
    "        if n_i == de_vocab['</s>']:\n",
    "            break\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[n_i]])) # Chosen word is next input\n",
    "\n",
    "        if use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "\n",
    "            \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:46:05.113702Z",
     "start_time": "2018-03-28T04:46:05.104461Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_sentence(s):\n",
    "    valid_sentence = s\n",
    "    \n",
    "    output_words = evaluate(valid_sentence)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', valid_sentence)\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:46:05.175000Z",
     "start_time": "2018-03-28T04:46:05.117996Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   0\n",
      " 499\n",
      "   9\n",
      "   0\n",
      "   6\n",
      "  60\n",
      "  11\n",
      "   9\n",
      "   0\n",
      "[torch.LongTensor of size (9,)]\n",
      "\n",
      "\n",
      " 202\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 30\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 895\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "> i am a student and he is a teacher\n",
      "< Zimmerbeschreibung : A <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_sentence('i am a student and he is a teacher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T04:46:05.235649Z",
     "start_time": "2018-03-28T04:46:05.179134Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0\n",
      " 11\n",
      " 91\n",
      "  0\n",
      "  6\n",
      " 75\n",
      " 47\n",
      "  0\n",
      " 11\n",
      "  0\n",
      "[torch.LongTensor of size (10,)]\n",
      "\n",
      "\n",
      " 202\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 30\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 895\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.cuda.LongTensor of size () (GPU 0)]\n",
      "\n",
      "> luck is no excuse and who has luck is successful\n",
      "< Zimmerbeschreibung : A <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_sentence('luck is no excuse and who has luck is successful')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "notify_time": "5",
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "518px",
    "left": "0px",
    "right": "1112px",
    "top": "111px",
    "width": "189px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
