{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Import\n",
    "- Read data (vocab, sentences)\n",
    "- Build model\n",
    "- Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:13.495418Z",
     "start_time": "2018-03-22T04:52:13.490770Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "batch_size = 1\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T04:01:55.240626Z",
     "start_time": "2018-03-21T04:01:55.235314Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:13.947269Z",
     "start_time": "2018-03-22T04:52:13.499028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "\n",
    "import scripts.text\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:13.956175Z",
     "start_time": "2018-03-22T04:52:13.951414Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path = './processed-data/id.1000/'\n",
    "en_vocab_path = data_path + 'train.10k.en.vocab'\n",
    "de_vocab_path = data_path + 'train.10k.de.vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:13.984203Z",
     "start_time": "2018-03-22T04:52:13.957901Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading vocab file ./processed-data/id.1000/train.10k.en.vocab ...\n",
      "  num words = 1000\n",
      "# Loading vocab file ./processed-data/id.1000/train.10k.de.vocab ...\n",
      "  num words = 1000\n"
     ]
    }
   ],
   "source": [
    "en_words, en_vocab, _ = scripts.text.load_vocab(en_vocab_path)\n",
    "de_words, de_vocab, _ = scripts.text.load_vocab(de_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:14.519796Z",
     "start_time": "2018-03-22T04:52:13.987125Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read train data\n",
    "en_train_sentences = []\n",
    "with open(data_path + 'train.10k.en', 'r') as f:\n",
    "    for line in f:\n",
    "        en_train_sentences.append(map(lambda x: int(x), line.split()))\n",
    "        \n",
    "de_train_sentences = []\n",
    "with open(data_path + 'train.10k.de', 'r') as f:\n",
    "    for line in f:\n",
    "        de_train_sentences.append(map(lambda x: int(x), line.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:14.530802Z",
     "start_time": "2018-03-22T04:52:14.523550Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read validation data\n",
    "en_valid_sentences = []\n",
    "with open(data_path + 'valid.100.en', 'r') as f:\n",
    "    for line in f:\n",
    "        en_valid_sentences.append(line.split())\n",
    "        \n",
    "de_valid_sentences = []\n",
    "with open(data_path + 'valid.100.de', 'r') as f:\n",
    "    for line in f:\n",
    "        de_valid_sentences.append(line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:14.575783Z",
     "start_time": "2018-03-22T04:52:14.534699Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Model's encoder using RNN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n",
    "\n",
    "    def forward(self, input_sentence, hidden):\n",
    "        sentence_len = len(input_sentence)\n",
    "        \n",
    "        embedded = self.embedding(input_sentence)\n",
    "        embedded = embedded.view(sentence_len, batch_size, -1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:14.613433Z",
     "start_time": "2018-03-22T04:52:14.589540Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Model's decoder using RNN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_vector, hidden):\n",
    "        output = self.embedding(input_vector).view(1, batch_size, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output = self.log_softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Checking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T06:47:13.050299Z",
     "start_time": "2018-03-21T06:47:13.043015Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 20, 2)\n",
    "decoder_test = DecoderRNN(10, 20, 10, 2)\n",
    "print(encoder_test)\n",
    "print(decoder_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T06:47:17.096257Z",
     "start_time": "2018-03-21T06:47:13.054397Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "if use_cuda:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3, 4]))\n",
    "decoder_hidden = encoder_hidden\n",
    "\n",
    "if use_cuda:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "\n",
    "for i in range(4):\n",
    "    decoder_output, decoder_hidden = decoder_test(word_inputs[i], decoder_hidden)\n",
    "    print(decoder_output)\n",
    "    print(decoder_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:14.621476Z",
     "start_time": "2018-03-22T04:52:14.617324Z"
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:14.665890Z",
     "start_time": "2018-03-22T04:52:14.625513Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # Zero gradient\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Prepare input for decoder and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[en_vocab['<s>']]]))\n",
    "    decoder_hidden = encoder_hidden  # Use last hidden from the encoder\n",
    "\n",
    "    if use_cuda:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: use the ground-truth target as the next input\n",
    "        for d_i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[d_i])\n",
    "            decoder_input = target_variable[d_i]\n",
    "    else:\n",
    "        # Without teacher forcing use its own predictions as the next input\n",
    "        for d_i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "#             print(decoder_output)\n",
    "            loss += criterion(decoder_output, target_variable[d_i])\n",
    "            # Pick most likely word index (highest value) from output (greedy search)\n",
    "            top_value, top_index = decoder_output.data.topk(1)\n",
    "            n_i = top_index[0][0]\n",
    "#             print(n_i)\n",
    "#             print(torch.LongTensor([n_i]))\n",
    "            decoder_input = Variable(torch.LongTensor([[n_i]])) # Chosen word is next input\n",
    "            \n",
    "            if use_cuda:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targers)\n",
    "            if n_i == en_vocab['</s>']:\n",
    "                break\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:18.430037Z",
     "start_time": "2018-03-22T04:52:14.669866Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_size = 200\n",
    "hidden_size = 250\n",
    "num_layers = 1\n",
    "dropout_p = 0.05\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(len(en_vocab), embedding_size, hidden_size, num_layers)\n",
    "decoder = DecoderRNN(embedding_size, hidden_size, len(de_vocab), num_layers)\n",
    "\n",
    "# Move models to GPU\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "# Initialize parameters and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-22T04:52:18.439246Z",
     "start_time": "2018-03-22T04:52:18.433791Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "num_epochs = 1\n",
    "plot_every = 100\n",
    "print_every = 100\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print every\n",
    "plot_loss_total = 0 # Reset every plot every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T04:52:13.504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all sentences to Variable\n",
    "if use_cuda:\n",
    "    for i in range(len(en_train_sentences)):\n",
    "        en_train_sentences[i] = Variable(torch.LongTensor(en_train_sentences[i]).view(-1, 1)).cuda()\n",
    "        de_train_sentences[i] = Variable(torch.LongTensor(de_train_sentences[i]).view(-1, 1)).cuda()\n",
    "else:\n",
    "    for i in range(len(en_train_sentences)):\n",
    "        en_train_sentences[i] = Variable(torch.LongTensor(en_train_sentences[i]).view(-1, 1))\n",
    "        de_train_sentences[i] = Variable(torch.LongTensor(de_train_sentences[i]).view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-22T04:52:13.512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Time: 0m 10s (- 17m 41s), Step: 100/10000, train_loss: 5.3789\n",
      "Epoch 0/1, Time: 0m 20s (- 16m 25s), Step: 200/10000, train_loss: 4.4344\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(0, num_epochs):\n",
    "    # Shuffle\n",
    "    indexes = np.arange(0, len(en_train_sentences))\n",
    "    np.random.shuffle(indexes)\n",
    "    step = 1\n",
    "    num_steps = math.ceil(len(en_train_sentences) / batch_size)\n",
    "    for index in indexes:\n",
    "        input_variable = en_train_sentences[index]\n",
    "        target_variable = de_train_sentences[index]\n",
    "        loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if step == 0:\n",
    "            step += 1\n",
    "            continue\n",
    "        \n",
    "        if step % print_every == 0 or step == num_steps:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print_summary = 'Epoch %s/%s, Time: %s, Step: %d/%d, train_loss: %.4f' % (epoch, num_epochs,\n",
    "                                                                utils.time_since(start, step / num_steps),\n",
    "                                                                step,\n",
    "                                                                num_steps, print_loss_avg)\n",
    "            print(print_summary)\n",
    "        \n",
    "        if step % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total\n",
    "        step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "notify_time": "5",
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
